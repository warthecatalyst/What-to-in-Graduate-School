# 项目和实习经历
## 阿里云-弹性计算-异常调度平台实习经历
### 异常调度平台是做什么的
异常调度平台式作为弹性计算的稳定性部门，其支撑了整个弹性计算百万台级别服务器的异常处理，包括流控、诊断、灰度发布等一系列业务。

### 全链路诊断是做什么的
全链路诊断业务主要负责的是从用户申请到底层物理机一整条链路上问题的发现和自动处理。在全链路诊断业务出现之前，对弹性计算的值班人员打扰度太大，并且问题的发现和处理也可能不及时。全链路诊断全面解放了值班人员，是我们异常调度平台的核心业务板块。

### 实习主要负责的任务模块
我主要负责的模块是异常特征的迁移。将异常特征从业务侧python模块迁移至横向侧的Java后端，加速查询性能、提高安全性、开放性。

**异常特征是什么**
异常特征是全链路诊断业务下的一个专家规则，把全链路诊断上不同模块的异常整理成为一个泛化的模块进行统一整理。异常特征定义有哪些字段：异常的有效时间，异常类别，触发条件，限制条件，是否严格匹配，对应的运维策略。

**为什么目前需要迁移**
最开始的异常特征是一个自包含的定义方式，作为当前项目的一个配置项，每次查询都要从diamond配置中心进行获取，因此只有我们自己团队内部在使用。但是现在希望把异常特征能够开放给弹性计算所有大团队去进行接入。目前特征定义方式的审批是git code review，无法正确记录修改人和审批人都是谁，系统的安全性、可审计性都较差。并且目前性能上也有一些缺陷，在异常特征数目增加到千条以上时，每次通过网络HTTP请求返回所有的异常特征配置是一个比较慢的过程，然后再在内存中进行全量的字符串正则表达式匹配，这样的匹配是比较慢的一个过程。迁移之后把这个匹配的任务放到mysql当中去做，通过mysql的一些优化手段去加速这个查询过程。

**高可用性策略**
系统的高可用性主要集中于服务的高可用性，原先的查询链路并没有被删除，当Java服务不可用时，转回原有的查询链路，只不过现在原有的查询链路不再有redis进行缓存。

**迁移结果**
所有代码全部上线之后进行了简单的压力测试，在QPS==1000的情况下系统能够无压力运行。

## 项目经历-极简版抖音后端
### 最终一致性方案设计
点赞场景的读写分离架构，缓存-数据库最终一致性方案的设计：
最终一致性方案借鉴了类似于两阶段提交的思路：
系统有多个集群，每个集群通过主节点向外部通信。在系统多个集群中，主要集群被成为alpha集群。
alpha节点运行一个分布式的定时任务，每15分钟进行一次全集群的同步。所有集群的redis都存放着两个key，basic favourite count表示的是视频的基本点赞数(例如视频1之前总共被点赞1000次)；以及additional favourite count表示在这段时间之内视频的新增点赞数。

alpha集群首先先向所有在etcd中注册过的其他集群主节点发送一条prepare消息，然后其他集群的主节点就会通过rpc流式返回所有过去15分钟之内的新增点赞数。alpha集群的主节点收到所有这些消息之后，会将所有的结果进行汇总。汇总完成之后，再把结果发送给成功返回结果的集群，然后将该结果加到basic favourite count当中，并且在additional favourite count中减去此次发送的点赞数(因为在同步的过程中集群仍然能收到点赞，这些点赞数不能够消失)。

**负载均衡怎么做的**
负载均衡通过etcd的round robin的策略做的，grpc没有实现具体的负载均衡策略，但是提供了自己的设计思路。已经为命名解析和负载均衡提供了接口。 我们可以用etcd方便的实现gRPC的负载均衡和服务发现。

**后续还有哪些可以优化的点**
目前的主要问题在于alpha集群是固定的，当主集群宕机是系统不可用。可以引入raft一致性算法。

### 系统瓶颈在哪里
目前系统的瓶颈主要在网关层，其主要原因是，当每次请求到来时，都要通过gprc客户端去访问一次etcd，通过etcd的返回结果。因此打算后续自己去通过一致性hash环去实现一个负载均衡，然后网关通过心跳检测的方式去检测服务是否仍然存活，这样就能够免去一直访问etcd了。

# 场景设计题
## topk系列问题
### 10亿个数找到最大的10个
这道题的思路是，先拿10个数建堆，然后一次添加剩余元素，如果大于堆顶的数（10中最小的），将这个数替换堆顶，并调整结构使之仍然是一个最小堆，这样，遍历完后，堆中的10个数就是所需的最大的10个。

### 有十万个单词，找出重复次数最高十个
针对top k类问题，通常比较好的方案是【分治+trie树/hash+小顶堆】，即先将数据集按照hash方法分解成多个小数据集，然后使用trie树或者hash统计每个小数据集中的query词频，之后用小顶堆求出每个数据集中出频率最高的前K个数，最后在所有top K中求出最终的top K。